{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imperative vs. Symbolic (non-compiled vs. compiled)"
      ],
      "metadata": {
        "id": "g1p8P6-f7Jgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install d2l==1.0.0a0"
      ],
      "metadata": {
        "id": "W--NHUX27TXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qTJonD_x7E6G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Factory for networks\n",
        "def get_net():\n",
        "    net = nn.Sequential(nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2))\n",
        "    return net\n",
        "\n",
        "x = torch.randn(size=(1, 512))"
      ],
      "metadata": {
        "id": "98tgfO8S7Zn8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convenience function for benchmarking\n",
        "class Benchmark:\n",
        "    \"\"\"For measuring running time.\"\"\"\n",
        "    def __init__(self, description='Done'):\n",
        "        self.description = description\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.timer = d2l.Timer()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        print(f'{self.description}: {self.timer.stop():.4f} sec')"
      ],
      "metadata": {
        "id": "aisJXFrp7gcC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = get_net()\n",
        "with Benchmark('Without torchscript'):\n",
        "    for i in range(1000): net(x)\n",
        "\n",
        "net = torch.jit.script(net)\n",
        "with Benchmark('With torchscript'):\n",
        "    for i in range(1000): net(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQYJrFNc7n4D",
        "outputId": "062983ce-a6fd-4201-c4cf-e0078aba2079"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without torchscript: 0.1740 sec\n",
            "With torchscript: 0.1649 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.save('my_mlp')\n",
        "%ls -lh my_mlp*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4QZtNUu9ImV",
        "outputId": "85a55c3a-c881-454f-b111-978622332b20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 651K Jun 12 18:54 my_mlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Asynchronous"
      ],
      "metadata": {
        "id": "-164rYT_-d_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import numpy\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "lLE-b0Ev9U02"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = d2l.try_gpu()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEDpGTzh-l8e",
        "outputId": "43f6d67a-0702-44c4-9fe3-82fb846e030e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with Benchmark('Numpy on CPU'):\n",
        "    for _ in range(10):\n",
        "        a = numpy.random.normal(size=(1000, 1000))\n",
        "        b = numpy.dot(a, a)\n",
        "\n",
        "with Benchmark(f'Pytorch on {device}'):\n",
        "    for _ in range(10):\n",
        "        a = torch.randn(size=(1000, 1000))\n",
        "        b = torch.mm(a, a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxYixYBW_dk3",
        "outputId": "ed6d605d-f367-462c-e96c-16316db189b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy on CPU: 1.6497 sec\n",
            "Pytorch on cuda:0: 0.5682 sec\n"
          ]
        }
      ]
    }
  ]
}