{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ashkan-mokarian/d2l-pytorch/blob/main/chapter_builder_guide/1_io.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u-vuaOj-tGE4"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q9tFrwT24sXx"
      },
      "outputs": [],
      "source": [
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOiUMnIx4z_b",
        "outputId": "f820962b-4a25-479d-dc46-e746d48750af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "x2 = torch.load('x-file')\n",
        "print(x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADIW5fTg486y",
        "outputId": "5a38754a-63c8-403b-f213-ccf0e0dba36d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'x': tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]]), 'y': tensor([1., 1., 1., 1., 1.])}\n"
          ]
        }
      ],
      "source": [
        "my_dict = {'x': torch.zeros(3,5), 'y': torch.ones(5)}\n",
        "torch.save(my_dict, 'dict-file')\n",
        "loaded_dict = torch.load('dict-file')\n",
        "print(loaded_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z0C0MAss5ORl"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eNr8_KN35vsm"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.LazyLinear(256)\n",
        "        self.out = nn.LazyLinear(10)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.out(F.relu(self.hidden(X)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Rx_06y26Y9S",
        "outputId": "f919812e-a0da-45ef-b8e8-fde6c2c6aefe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3620, -0.5910,  0.0919, -0.0287,  0.2053,  0.2669,  0.3183, -0.0139,\n",
            "         -0.0164, -0.5032],\n",
            "        [ 0.1654, -0.1625, -0.0626,  0.0124,  0.1308,  0.2323,  0.0149,  0.2468,\n",
            "          0.0492, -0.1549],\n",
            "        [ 0.2316, -0.2959, -0.1268, -0.1075, -0.3235,  0.1609, -0.0161, -0.2080,\n",
            "         -0.2984, -0.3073]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MLP()\n",
        "X = torch.randn((3, 10))\n",
        "y_orig = model(X)\n",
        "print(y_orig)\n",
        "\n",
        "torch.save(model.state_dict(), 'model.dict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeHpyoPE-NRy",
        "outputId": "555d2fc3-e06e-49f7-8a95-40cd51b038b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
            "  (out): LazyLinear(in_features=0, out_features=10, bias=True)\n",
            ")\n",
            "MLP(\n",
            "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
            "  (out): LazyLinear(in_features=0, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('model.dict'))\n",
        "print(clone)\n",
        "clone.eval()\n",
        "print(clone)\n",
        "y_clone = clone(X)\n",
        "y_clone == y_orig"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
